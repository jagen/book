{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第五章 手写板功能\n",
    "\n",
    "## 5.1 MNIST介绍\n",
    "\n",
    "## 5.2 使用TensorFlow完成实验\n",
    "\n",
    "## 5.3 神经网络为什么那么强\n",
    "\n",
    "**如果你提供的训练数据向量在标签分类的过程中，没办法使得信息熵下降，那就没办法训练出好的模型。**\n",
    "\n",
    "丰富的VC维会让网络出于容易过拟合的状态。过拟合是几乎所有的机器学习算法中都有可能遇到的问题。\n",
    "\n",
    "要在网络中提供丰富的VC维————通常的手段就是加深网络的深度，加多神经元的数量。粗略估量一下，如果一个神经元能够成功分开两个分类输出1和0————$2^1$，那么两个神经元理论上能够成功分开4个分类————$2^2$，1000个神经元就是$2^{1000}$个分类————大概是$1\\times10^{301}$这么多。\n",
    "\n",
    "拥有如此好的分类会带来两个问题：\n",
    "\n",
    "**其一**，在这么复杂的网络中，如此多的$w$已经早就没有了统计学中的权值权重的意义，无法得到清晰的物理解释，也无法有效进行逆向研究。所以深度学习的模型训练得再好也只能当成一个黑匣子来使用。\n",
    "\n",
    "**其二**，这种拥有极高的VC维的网络能够学到很多东西，包括那些样本中所包含的噪声信息或者特例信息，这是极为糟糕的事情。这种学习能力通常会导致，你把个案性的训练样本给到神经网络，它能把每个个案中的特点都牢牢记下来，在训练集上的$Loss$能保证很低，识别率极高，但是换个新样本来让它识别，它就会严重误判。\n",
    "\n",
    "过拟合的原因：样本过少，不足以总结归纳其共性。参数过多，能够拟合极为复杂的特征的内容。\n",
    "改善方案：增加样本数量，理论上是越多越好。\n",
    "检查手段：拿一些样本来验证一下。\n",
    "\n",
    "在现在以深度学习为技术基础的工程实现方面，通常会把拿到的所有样本数分为下面三个集合。\n",
    "\n",
    "1. 训练集（training set）：用来学习的样本集，通过这些向量来确定网络中的各个特定系数。\n",
    "2. 验证集（validation set）：是用来调整分类器的参数的样本集，在训练的过程中，网络模型会立刻在验证集进行验证。我们会同步观察到在这个验证集数据上模型的表现如何，损失函数值是否会下降，准确率是否在提高。\n",
    "3. 测试集（test set）：测试集则是在训练后为测试模型的能力（主要是分类能力）而设置的一部分数据集合。\n",
    "\n",
    "通常训练集会在所有样本中占大头，例如50%、60%抑或更多。验证集和测试集相对都比较小，大概数量级别是在25%、20%甚至有可能更少一些。\n",
    "\n",
    "验证集是我们在深度学习中预防过拟合的手段之一，也可以说是深度学习训练过程中的标配。"
   ]
  }
 ]
}