# 深度学习是什么

## 2.1 神经网络是什么

神经网络是一种人类由于受到生物神经细胞结构启发而研究出的一种算法体系。

### 2.1.1 神经元

一个神经元就是一个线性回归模型+**激励函数**。

### 2.1.2 激励函数

激励函数（activation function)————也有翻译成激活函数的，也是神经元中重要的组成部分。激励函数在一个神经元当中跟随在f(x)=wx+b函数之后，用来加入一些非线性的因素。

1. Sigmoid函数，最早应用的激励函数。z=wx+b, f(z)=1/(1+e^-z)
2. Tanh函数，双曲正切函数，循环神经网络RNN会用到。tanh(x)=(e^x-e^-x)/(e^x+e^-x)
3. ReLU函数，目前大部分卷积神经网络CNN中喜欢使用的激励函数。y=max(x,0)
4. Linear函数。该函数在实际应用中并不多，它会导致严重的欠拟合现象。

### 2.1.3 神经网络

一旦多个神经元收尾连接形成一个类似网络的结构来协同工作的时候，那就可以被称为神经网络了。

学习神经网络的整理历程中会发现这样或那样的不同形式的网络，每种网络或出自某个具体的工程项目，根据需求、工程人员经验、实验效果来选定的，或者出自某些尖端的实验室（例如谷歌、微软以及国内一些顶级企业等），并辅以相关的论文对网络在实验中效果与同期其他网络解决方案做对比。但是极少能发现在这些网络的诞生过程中有完整的、严谨的、普适的、毋庸置疑的推导过程————也难怪有不少从事深度学习多年的资深老兵说深度学习越学越像老中医。

在一个神经网络中通常会分这样几层：输入层、隐藏层和输出层。

**输入层**在整个网络的最前端部分，直接接受输入的向量，它是不对数据做任何处理的，所以通常这一层不计入层数。

**隐藏层**可以有一层或多层，现在比较深的网络有超过50层的。

**输出层**是最后一层，用来输出整个网络处理的值，这个值可能是一个分类向量值，也可能是一个类似线性回归那样产生的连续的值，也可能是别的复杂类型的值或者向量，根据不同的需求输出层的构造也不尽相同。

## 2.2 深度神经网络

所谓的深度学习实际指的是基于深度神经网络（deep neural network， DNN）的学习，也就是深度人工神经网络所进行的学习过程，或者称作Deep Learning。

传统机器学习在训练的过程中需要很少的样本向量，通常都是百级或者千级就够了，这对于深度学习来说也是无法做到的————它需要数以万计的样本来做训练。所以，大家千万不要盲目迷信深度学习的能力，也不要误读了深度学习的作用。

## 2.3 深度学习为什么这么强

神经网络，尤其是深度神经网络之所以这么吸引人，主要是因为它能够通过大量的线性分类器和非线性关系的组合来完成平时非常棘手的线性不可分的问题。

### 2.3.1 不用再提取特征

### 2.3.2 处理线性不可分
